{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Day 2: Fitting distributions\n",
    "\n",
    "## Objectives:\n",
    "* Talk a bit about errors in Python\n",
    "* Look at fitting simple distributions, binned and unbinned\n",
    "* Mention other libraries for fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on terminology\n",
    "\n",
    "I try to introduce the relevant terminology when we talk about new subject.\n",
    "\n",
    "This is not meant to spew jargon at you, but rather to give you something you can Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "\n",
    "* The most serious sort of error: A segfault\n",
    "    - Issue with the underlying compiled code\n",
    "    - *Very* rare in Python itself, can be intentionally caused or a bug in libraries\n",
    "* Most errors are \"Exceptions\": A control flow feature in Python - and you can act on and work with them!\n",
    "    - You can even use Exceptions for things that are not errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions\n",
    "\n",
    "Exceptions are designed to interrupt the control flow for \"exceptional\" events. This makes writing safe code much easier - could you imagine if every function had to return an error status, and you had to check the status and also return your own error status if it was bad? (If you can imagine it, congratulations, you can write C code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    s = 0\n",
    "    for i in range(10):\n",
    "        if x == 0:\n",
    "            return 0, \"Error in calculations\"\n",
    "        s += i / x\n",
    "    return s, \"\"\n",
    "\n",
    "value, error = f(0)\n",
    "\n",
    "if error:\n",
    "    print(error)\n",
    "else:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    s = 0\n",
    "    for i in range(10):\n",
    "        if x == 0:\n",
    "            raise RuntimeError(\"Error in calculations\")\n",
    "        s += i / x\n",
    "    return s\n",
    "\n",
    "try:\n",
    "    value = f(0)\n",
    "    print(value)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefits to the second example:\n",
    "\n",
    "* This nests; the in-between functions don't need to know about the Exception in the inner function or the check in the outer function\n",
    "    - Exceptions just bubble up through the stack\n",
    "* This keeps errors from interfering with the function return values\n",
    "* If we remove the Exception checking, we get a Python error message\n",
    "* If we remove the check, Python automatically throws an exception when you divide by zero!\n",
    "* The code is faster if we don't throw an exception often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    s = 0\n",
    "    for i in range(10):\n",
    "        if x == 0:\n",
    "            raise RuntimeError(\"Error in calculations\")\n",
    "        s += i / x\n",
    "    return s\n",
    "\n",
    "value = f(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    s = 0\n",
    "    for i in range(10):\n",
    "        s += i / x\n",
    "    return s\n",
    "\n",
    "value = f(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we see that Python has a ZeroDivisionError, and it is raised when you divide by zero. So we can now make a function that can take 0's without making an explicit check for 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_xy(vec):\n",
    "    \"\"\"\n",
    "    This takes a direction vector vec[0], vec[1], vec[2], and\n",
    "    returns the x and y componets of a vector with length 1 z component.\n",
    "    If the length of z is 0, returns [0,0].\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return vec[0]/vec[2], vec[1]/vec[2]\n",
    "    except ZeroDivisionError:\n",
    "        return vec[0]*0, vec[1]*0\n",
    "    \n",
    "def direction_xy_classic(vec):\n",
    "    if vec[2] == 0:\n",
    "        return vec[0]*0, vec[1]*0\n",
    "    else:\n",
    "        return vec[0]/vec[2], vec[1]/vec[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version that does not check will be faster when the exception is not caught - you are not paying for an extra check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "direction_xy((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "direction_xy_classic((1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the exception catching mechanism is slower than the normal control flow if it does get caught a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "direction_xy((1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "direction_xy_classic((1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception throwing\n",
    "\n",
    "You have a large collection of standard exceptions in Python:\n",
    "\n",
    "* <https://docs.python.org/3.7/library/exceptions.html>\n",
    "\n",
    "You can make a new one trivially:\n",
    "\n",
    "```python\n",
    "class MyException(RuntimeError):\n",
    "    pass\n",
    "```\n",
    "\n",
    "### Exception catching\n",
    "\n",
    "You put the code that might throw an exception in a `try:` block.\n",
    "\n",
    "You put the possible exception catching parts in one or more `except Name:` block following that. It contains the name of the exception type - you can list multiple exception type to catch, and any subclasses will also be caught. You can optionally keep a reference to the exception to use by using `as`. You can even reraise the exception with `raise`. You can also `raise Err() from y` (Python 3) to give users a more explicit traceback. Or `raise Err() from None` to give a less explicit traceback (hides the original exception).\n",
    "\n",
    "You optionally can put in a `else` block which runs if no exceptions were caught, and a `finally` block, which runs no-matter-what (for cleanup, usually). See [this or PEP 341](https://docs.python.org/2.5/whatsnew/pep-341.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a playground for you. Try changing the caught exception type to `RuntimeError` and then another type of error, and experiment a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyException(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def f():\n",
    "    raise MyException()\n",
    "    \n",
    "try:\n",
    "    f()\n",
    "except MyException:\n",
    "    print(\"Caught Exception!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common example: Optional import\n",
    "\n",
    "Let's say you want to import a package, but you are fine if it doesn't exist - you'll just deactivate some features. Here's the standard way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import some_fancy_printout_package_that_does_not_exist\n",
    "except ImportError:\n",
    "    some_fancy_printout_package_that_does_not_exist = None\n",
    "    \n",
    "if some_fancy_printout_package_that_does_not_exist:\n",
    "    print(\"Using fancy printout\")\n",
    "else:\n",
    "    print(\"Not using fancy printout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, it is often **better to ask for forgiveness than to ask for permission**.\n",
    "\n",
    "This is can be better in more ways than just performance. What happens if you check for the existence of a file, find it exists, then try to open it, just to find it was deleted in the meantime?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warnings\n",
    "\n",
    "Warnings are special - since they should not interrupt the control flow normally. So Python provides a `warning` module, with a `warn` function. It print a message unless you request warnings to be treated as errors, in which case it raises an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting distributions\n",
    "\n",
    "We can fit distributions with Python - though we'll need to look around a bit to find good ways to fit more complex distributions. Let's try the simplest case and SciPy first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_X = norm.rvs(1,2,100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gauss_X, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sigma = norm.fit(gauss_X)\n",
    "print(f\"mean = {mean}, sigma = {sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have no error information, no pretty much anything... Just a result.\n",
    "\n",
    "And, we can make a ND Gaussian, including covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = multivariate_normal.rvs([1,2], cov=[[.5,.3],[.3,2]], size=100_000)\n",
    "plt.hist2d(*XY.T, bins=100)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But... Multivariate norm is missing a fit function! Ugh..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting by hand\n",
    "\n",
    "You already know how to bin and fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit, minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder, curve fits wants a function that take 1 data parameter followed by functional parameters:\n",
    "\n",
    "<!--\n",
    "vals, edges = np.histogram(gauss_X, bins=25)\n",
    "errs = 1/np.sqrt(vals)\n",
    "vals = vals / np.sum(vals) / (edges[1] - edges[0])\n",
    "centers = (edges[1:] + edges[:-1])/2\n",
    "curve_fit(norm.pdf, centers, vals, [1,1], sigma=errs)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, edges = np.histogram(gauss_X, bins=25, density=True)\n",
    "centers = (edges[1:] + edges[:-1])/2\n",
    "curve_fit(norm.pdf, centers, vals, [1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(edges[0], edges[-1], 500)\n",
    "plt.plot(xs, norm.pdf(xs, 1, 2))\n",
    "plt.plot(centers, vals, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbinned is not quite as easy, but we can still do it explicitly. We want to minimize an NLL:\n",
    "\n",
    "$$\n",
    "NLL = -\\sum_i \\ln\\left( P(x_i) \\right)\n",
    "$$\n",
    "\n",
    "The minimize function in scipy.optimize takes:\n",
    "\n",
    "* A function to minimize. It must take an iterable of parameters as the first argument. You can pass through other arguments using `args`.\n",
    "* An initial guess for parameters\n",
    "* Optional args to pass through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL_gauss(params, x):\n",
    "    mu, sigma = params\n",
    "    y = norm.pdf(x, mu, sigma)\n",
    "    return -np.sum(np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(NLL_gauss, [.9, 1.8], args=(gauss_X,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try methods to fix the `success=False`:\n",
    "\n",
    "* Set a low `tol=` parameter\n",
    "* Increase the number of samples\n",
    "* Try `method = 'Nelder-Mead'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: we've skipped something important by using the Gaussian pdf from Scipy: It is normalized! We need normalized PDF functions for this to work. If you write your own, you need a normalized function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tools\n",
    "\n",
    "So, this can be done by hand; but several things are missing:\n",
    "\n",
    "* Easy ways to build distribution PDFs, especially combinations\n",
    "    * Even would be nicer if high-speed/GPU calculations possible\n",
    "* Extra error information, including asymmetric errors\n",
    "* Pretty fitting API\n",
    "* Better parameter limit control, and nice API\n",
    "* Automatic derivatives of fitting function (though you can pass a manual one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages exist:\n",
    "\n",
    "* [LMFit][]: Seems to be one of the common tools outside of HEP - it doesn't seem to like unbinned fits, though.\n",
    "* [iMinuit][] and [probfit][]: HEP tools made available to normal Pythonistas. Probfit pip package broken on Python 3.\n",
    "* [RooFit][]: A ROOT tool for fitting. Very powerful, very slow, very hard to install and keep from segfaulting\n",
    "* [GooFit][]: A GPU/OpenMP tool, fast but new PDFs must be added in C++/CUDA.\n",
    "\n",
    "[LMFit]: http://cars9.uchicago.edu/software/python/lmfit_MinimizerResult/index.html\n",
    "[iMinuit]: https://iminuit.readthedocs.io/en/latest/\n",
    "[probfit]: https://probfit.readthedocs.io/en/latest/\n",
    "[RooFit]: http://roofit.sourceforge.net\n",
    "[GooFit]: https://goofit.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general design is somewhat similar. You need the following pieces:\n",
    "\n",
    "* Parameters: variables you minimize\n",
    "* Data: The input data - often provides Observables for each dimension\n",
    "* Models: Common \"parts\" that you can combine\n",
    "* Normalization: When fitting, you need to normalize for the NLL to work. (Missing in LMFit?)\n",
    "* Fitter: something to do the fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run once if you need this\n",
    "#!pip install --user lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import GaussianModel, LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_part = np.random.normal(1,2,size=100_000)\n",
    "lin_part = np.random.uniform(low=-10,high=10,size=50_000)\n",
    "total_rand = np.concatenate([gauss_part, lin_part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianModel(prefix=\"gauss_\") + LinearModel(prefix=\"lin_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, edges = np.histogram(total_rand, bins=25, density=True)\n",
    "centers = (edges[1:] + edges[:-1])/2\n",
    "res = model.fit(vals, x=centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10)\n",
    "y = model.eval(params=res.params, x=x)\n",
    "plt.plot(x,y)\n",
    "plt.hist(total_rand, bins=25, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probfit\n",
    "\n",
    "If you do want to try probfit: The latest git version supports Python 3 (last release on PyPI: 2013). I'm bugging the new maintainer now. `pip install --user git+https://github.com/iminuit/probfit.git#egg=probfit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GooFit\n",
    "\n",
    "If you really want to try GooFit, you can try this on OSC:\n",
    "    \n",
    "```\n",
    "!pip install --user scikit-build cmake\n",
    "!PATH=$HOME/.local/bin:$PATH pip install --user --verbose goofit\n",
    "```\n",
    "\n",
    "The extra requirements here are partially to ensure it gets the highest level of optimization, and partially requirements that will eventually go away.\n",
    "\n",
    "If you are on macOS, scikit-build is broken, you'll need `!pip install scikit-build==0.6.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = goofit.Observable('x', -10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = goofit.UnbinnedDataSet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.from_matrix([total_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goofit.PolynomialPdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = goofit.Variable(\"a\", 0, 0, 1)\n",
    "linear = goofit.PolynomialPdf('linear', x, [a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = goofit.Variable('mu', 0, -10, 10)\n",
    "sigma = goofit.Variable('sigma', 1, 0, 5)\n",
    "gauss = goofit.GaussianPdf('gauss', x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = goofit.Variable('frac', .5, 0, 1)\n",
    "total = goofit.AddPdf('tot', [frac], [gauss, linear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = total.fitTo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, pts = total.evaluatePdf(x)\n",
    "total.setData(grid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "v = ax.plot(grid.to_numpy().flatten(), pts, linewidth=2)[0]\n",
    "ax.set_xlabel('xvar')\n",
    "ax.set_ylabel('Normalized probability')\n",
    "ax.set_ylim(ymin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mimic OSC",
   "language": "python",
   "name": "sys_python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
